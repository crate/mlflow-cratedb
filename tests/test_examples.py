import logging
import sys
import time
from pathlib import Path

import pytest
import sqlalchemy as sa
from mlflow.store.model_registry.dbmodels.models import SqlRegisteredModel
from mlflow.store.tracking.dbmodels.models import SqlExperiment, SqlMetric, SqlParam, SqlRun
from mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore

from tests.util import process

# The test cases within this file exercise two different ways of recording
# ML experiments. They can either be directly submitted to the database,
# or alternatively to an MLflow Tracking Server.
MLFLOW_TRACKING_URI_SERVER = "http://127.0.0.1:5000"


logger = logging.getLogger(__name__)


def get_example_program_path(filename: str):
    """
    Compute path to example program.
    """
    return Path(__file__).parent.parent.joinpath("examples").joinpath(filename)


@pytest.mark.examples
def test_tracking_dummy(reset_database, engine: sa.Engine, tracking_store: SqlAlchemyStore, db_uri):
    """
    Run a dummy experiment program, without any data.
    Verify that the database has been populated appropriately.

    Here, no MLflow Tracking Server is used, so the `MLFLOW_TRACKING_URI`
    will be the SQLAlchemy database connection URI, i.e. the program will
    directly communicate with CrateDB.

    -- https://mlflow.org/docs/latest/tracking.html#backend-stores
    """

    # Invoke example program.
    tracking_dummy = get_example_program_path("tracking_dummy.py")
    logger.info("Starting experiment program")
    with process(
        [sys.executable, tracking_dummy],
        env={"MLFLOW_TRACKING_URI": db_uri},
        stdout=sys.stdout.buffer,
        stderr=sys.stderr.buffer,
    ) as client_process:
        client_process.wait(timeout=10)
        assert client_process.returncode == 0

    # Verify database content.
    with tracking_store.ManagedSessionMaker() as session:
        assert session.query(SqlExperiment).count() == 2
        assert session.query(SqlMetric).count() == 4
        assert session.query(SqlParam).count() == 5


@pytest.mark.examples
def test_tracking_merlion(reset_database, engine: sa.Engine, tracking_store: SqlAlchemyStore, db_uri):
    """
    Run a real experiment program, reporting to an MLflow Tracking Server.
    Verify that the database has been populated appropriately.

    Here, `MLFLOW_TRACKING_URI` will be the HTTP URL of the Tracking Server,
    i.e. the program will submit events and metrics to it, wrapping the
    connection to CrateDB.
    """
    tracking_merlion = get_example_program_path("tracking_merlion.py")
    cmd_server = [
        "mlflow-cratedb",
        "server",
        "--workers=1",
        f"--backend-store-uri={db_uri}",
        "--gunicorn-opts='--log-level=debug'",
    ]
    cmd_client = [
        sys.executable,
        tracking_merlion,
    ]

    logger.info("Starting server")
    with process(cmd_server, stdout=sys.stdout.buffer, stderr=sys.stderr.buffer, close_fds=True) as server_process:
        logger.info(f"Started server with process id: {server_process.pid}")
        # TODO: Wait for HTTP response.
        time.sleep(4)

        # Invoke example program.
        logger.info("Starting client")
        with process(
            cmd_client,
            env={"MLFLOW_TRACKING_URI": MLFLOW_TRACKING_URI_SERVER},
            stdout=sys.stdout.buffer,
            stderr=sys.stderr.buffer,
        ) as client_process:
            client_process.wait(timeout=120)
            assert client_process.returncode == 0

    # Verify database content.
    with tracking_store.ManagedSessionMaker() as session:
        assert session.query(SqlExperiment).count() == 2
        assert session.query(SqlMetric).count() == 4
        assert session.query(SqlParam).count() == 5

    with engine.begin() as conn:
        conn.execute(sa.text("REFRESH TABLE doc.anomalies"))
        conn.execute(sa.text("REFRESH TABLE testdrive.runs"))

        # Anomalies that have been manually annotated
        anomalies_manual = conn.execute(sa.text("SELECT * FROM doc.anomalies WHERE experiment_id IS NULL"))
        assert anomalies_manual.rowcount == 3

        # Count anomalies that have been generated by the latest run
        anomalies_generated = conn.execute(
            sa.text(
                """
                SELECT *
                FROM doc.anomalies
                WHERE experiment_id = (
                    SELECT experiment_id
                    FROM testdrive.runs
                    ORDER BY start_time DESC
                    LIMIT 1
                )
                """
            ),
        )
        assert anomalies_generated.rowcount >= 1


@pytest.mark.examples
@pytest.mark.slow
def test_tracking_pycaret(reset_database, engine: sa.Engine, tracking_store: SqlAlchemyStore, db_uri):
    """
    Run a real experiment program, reporting to an MLflow Tracking Server.
    Verify that the database has been populated appropriately.

    Here, `MLFLOW_TRACKING_URI` will be the HTTP URL of the Tracking Server,
    i.e. the program will submit events and metrics to it, wrapping the
    connection to CrateDB.
    """
    tracking_pycaret = get_example_program_path("tracking_pycaret.py")
    cmd_server = [
        "mlflow-cratedb",
        "server",
        "--workers=1",
        f"--backend-store-uri={db_uri}",
        "--gunicorn-opts='--log-level=debug'",
    ]

    cmd_client = [
        sys.executable,
        tracking_pycaret,
    ]

    logger.info("Starting server")
    with process(cmd_server, stdout=sys.stdout.buffer, stderr=sys.stderr.buffer, close_fds=True) as server_process:
        logger.info(f"Started server with process id: {server_process.pid}")
        # TODO: Wait for HTTP response.
        time.sleep(4)

        # Invoke example program.
        logger.info("Starting client")
        with process(
            cmd_client,
            env={"MLFLOW_TRACKING_URI": MLFLOW_TRACKING_URI_SERVER},
            stdout=sys.stdout.buffer,
            stderr=sys.stderr.buffer,
        ) as client_process:
            client_process.wait(timeout=480)
            assert client_process.returncode == 0

    with engine.begin() as conn:
        conn.execute(sa.text("REFRESH TABLE testdrive.experiments"))
        conn.execute(sa.text("REFRESH TABLE testdrive.metrics"))
        conn.execute(sa.text("REFRESH TABLE testdrive.params"))
        conn.execute(sa.text("REFRESH TABLE doc.sales_data_for_forecast"))

    with tracking_store.ManagedSessionMaker() as session:
        # We have 2 experiments - one for "Default" experiment and one for the example
        assert session.query(SqlExperiment).count() == 2, "experiments should have 2 rows"
        # We have 32 distinct runs in the experiment which produced metrics
        assert session.query(sa.func.count(sa.distinct(SqlMetric.run_uuid))).scalar() == 32, (
            "metrics should have 32 distinct run_uuid"
        )
        # We have 33 runs in total (1 parent + 32 child runs)
        assert session.query(SqlRun).count() == 33, "runs should have 33 rows"
        # We have 33 distinct runs which have parameters (1 parent + 32 child runs)
        assert session.query(sa.func.count(sa.distinct(SqlParam.run_uuid))).scalar() == 33, (
            "params should have 33 distinct run_uuid"
        )
        # We have one model registered
        assert session.query(SqlRegisteredModel).count() == 1, "registered_models should have 1 row"

    with engine.begin() as conn:
        # Test the demo data to make sure it was loaded correctly. No refresh required, as the example refreshes
        demo_data = conn.execute(sa.text("SELECT count(*) as ct FROM doc.sales_data_for_forecast")).fetchone()

        assert demo_data[0] == 9491, "demo data should have 9491 rows"
